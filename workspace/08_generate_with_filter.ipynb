{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate with filter\n",
    "\n",
    "GeneratorとFilterをつかって良い文書のみを生成する\n",
    "\n",
    "## Generatorのパラメータ\n",
    "\n",
    "|パラメータ名|内容|\n",
    "|:--|:--|\n",
    "| `num_layers` | transformerのパラメータ、[tensorflowのチュートリアル参照](https://www.tensorflow.org/tutorials/text/transformer) |\n",
    "| `GEN_d_model` | transformerの`d_model`パラメータ、[tensorflowのチュートリアル参照](https://www.tensorflow.org/tutorials/text/transformer) |\n",
    "| `dff` | transformerのパラメータ、[tensorflowのチュートリアル参照](https://www.tensorflow.org/tutorials/text/transformer) |\n",
    "| `num_heads` | transformerのパラメータ、[tensorflowのチュートリアル参照](https://www.tensorflow.org/tutorials/text/transformer) |\n",
    "| `GENERATOR_EPOCH` | Generatorのエポック数 |\n",
    "| `TEMPERATURE` | 生成するスレッドタイトルの多様性と尤度のトレードオフパラメータ（0.0以上）、0.0のとき最も確信度の高いスレッドのみを生成する |\n",
    "| `BATCH_NUM` | １回の生成に`BATCH_SIZE` * `BATCH_SIZE`個のスレッドを生成して、Filterのスコアが良いものを出力する |\n",
    "| `BATCH_SIZE` | １回の生成に`BATCH_SIZE` * `BATCH_SIZE`個のスレッドを生成して、Filterのスコアが良いものを出力する |\n",
    "\n",
    "## Filterのパラメータ\n",
    "\n",
    "|パラメータ名|内容|\n",
    "|:--|:--|\n",
    "| `conv_filters` | Filterのパラメータ、詳細は[scripts/model.py](scripts/model.py)を参照 |\n",
    "| `conv_kernel_sizes` | Filterのパラメータ、詳細は[scripts/model.py](scripts/model.py)を参照 |\n",
    "| `FLT_d_model` | Filterの`d_model`パラメータ、詳細は[scripts/model.py](scripts/model.py)を参照 |\n",
    "| `FILTER_EPOCH` | Filterのエポック数 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generatorモデルパラメータ\n",
    "num_layers = 4\n",
    "GEN_d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "GENERATOR_EPOCH = 37\n",
    "TEMPERATURE = 0.8\n",
    "BATCH_NUM = 40\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Filterモデルパラメータ\n",
    "conv_filters = [32, 64, 128]\n",
    "conv_kernel_sizes = [16, 8, 4]\n",
    "FLT_d_model = 128\n",
    "FILTER_EPOCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('sentencepiece.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weightファイル読み込みのために利用する\n",
    "with open(\"real_dataset.pickle\", \"rb\") as f:\n",
    "    ids = pickle.load(f)\n",
    "real_dataset_tensor = tf.keras.preprocessing.sequence.pad_sequences(ids, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データのパラメータ\n",
    "vocab_size = sp.get_piece_size()\n",
    "seq_len = real_dataset_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(num_layers, GEN_d_model, num_heads, dff, vocab_size, max_pos_encoding=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: create variables\n",
    "_ = generator(tf.constant(real_dataset_tensor[:1]), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(f'model/generator/weights_epoch{GENERATOR_EPOCH}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate with initial model\n",
    "generation_ids = generator.sample(num_sample=5, temperature=TEMPERATURE, padding=True)\n",
    "\n",
    "for ids in generation_ids:\n",
    "    ids_int = list(map(lambda x: int(x), ids))\n",
    "    print(sp.decode_ids(ids_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model import Filter\n",
    "nanj_filter = Filter(conv_filters, conv_kernel_sizes, FLT_d_model, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: create variables\n",
    "_ = nanj_filter(tf.constant(real_dataset_tensor[:1]), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanj_filter.load_weights(f'model/filter/weights_epoch{FILTER_EPOCH}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate with filter\n",
    "results = []\n",
    "for batch in range(BATCH_NUM):\n",
    "    generation_ids = generator.sample(num_sample=BATCH_SIZE, temperature=TEMPERATURE, padding=True)\n",
    "    scores = [float(v) for v in tf.math.sigmoid(nanj_filter(generation_ids, training=False))]\n",
    "    results.extend(list(zip(generation_ids, scores)))\n",
    "\n",
    "print(\">>> best 20 <<<\")\n",
    "for ids, score in sorted(results, key=lambda x: -x[1])[:20]:\n",
    "    text = sp.decode_ids(list(map(lambda x: int(x), ids)))\n",
    "    print(text, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = sp.encode_as_ids(\"三大\")\n",
    "\n",
    "results = []\n",
    "for batch in range(BATCH_NUM):\n",
    "    generation_ids = generator.sample(num_sample=BATCH_SIZE, temperature=TEMPERATURE, padding=True, prefix=prefix)\n",
    "    scores = [float(v) for v in tf.math.sigmoid(nanj_filter(generation_ids, training=False))]\n",
    "    results.extend(list(zip(generation_ids, scores)))\n",
    "\n",
    "\n",
    "print(\">>> best 20 <<<\")\n",
    "for ids, score in sorted(results, key=lambda x: -x[1])[:20]:\n",
    "    text = sp.decode_ids(list(map(lambda x: int(x), ids)))\n",
    "    print(text, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = sp.encode_as_ids(\"【なぞなぞ】\")\n",
    "\n",
    "results = []\n",
    "for batch in range(BATCH_NUM):\n",
    "    generation_ids = generator.sample(num_sample=BATCH_SIZE, temperature=TEMPERATURE, padding=True, prefix=prefix)\n",
    "    scores = [float(v) for v in tf.math.sigmoid(nanj_filter(generation_ids, training=False))]\n",
    "    results.extend(list(zip(generation_ids, scores)))\n",
    "\n",
    "print(\">>> best 20 <<<\")\n",
    "for ids, score in sorted(results, key=lambda x: -x[1])[:20]:\n",
    "    text = sp.decode_ids(list(map(lambda x: int(x), ids)))\n",
    "    print(text, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = sp.encode_as_ids(\"ぷよぷよ\")\n",
    "\n",
    "results = []\n",
    "for batch in range(BATCH_NUM):\n",
    "    generation_ids = generator.sample(num_sample=BATCH_SIZE, temperature=TEMPERATURE, padding=True, prefix=prefix)\n",
    "    scores = [float(v) for v in tf.math.sigmoid(nanj_filter(generation_ids, training=False))]\n",
    "    results.extend(list(zip(generation_ids, scores)))\n",
    "\n",
    "print(\">>> best 20 <<<\")\n",
    "for ids, score in sorted(results, key=lambda x: -x[1])[:20]:\n",
    "    text = sp.decode_ids(list(map(lambda x: int(x), ids)))\n",
    "    print(text, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = sp.encode_as_ids(\"【徹底討論】\")\n",
    "\n",
    "results = []\n",
    "for batch in range(BATCH_NUM):\n",
    "    generation_ids = generator.sample(num_sample=BATCH_SIZE, temperature=TEMPERATURE, padding=True, prefix=prefix)\n",
    "    scores = [float(v) for v in tf.math.sigmoid(nanj_filter(generation_ids, training=False))]\n",
    "    results.extend(list(zip(generation_ids, scores)))\n",
    "\n",
    "print(\">>> best 20 <<<\")\n",
    "for ids, score in sorted(results, key=lambda x: -x[1])[:20]:\n",
    "    text = sp.decode_ids(list(map(lambda x: int(x), ids)))\n",
    "    print(text, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
